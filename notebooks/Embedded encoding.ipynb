{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeded encoding\n",
    "### Edgar Acuna\n",
    "### April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering a dataset with 10 instances two numerical predictors  and one categorical atribute with two levels\n",
    "num_data = np.random.random(size=(10,2))\n",
    "#One categorical variables with 3 levels\n",
    "cat_data = np.array([\"red\",\"blue\",\"green\",\"red\",\"red\",\"blue\",\"blue\",\"green\",\"red\",\"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33411343, 0.80780972],\n",
       "       [0.02482294, 0.45455455],\n",
       "       [0.15375505, 0.77538588],\n",
       "       [0.04623018, 0.80065508],\n",
       "       [0.11466097, 0.73561668],\n",
       "       [0.09044322, 0.68652931],\n",
       "       [0.30915452, 0.54922504],\n",
       "       [0.61327427, 0.60722644],\n",
       "       [0.80411887, 0.85150846],\n",
       "       [0.12623851, 0.25971377]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 2, 0, 0, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing the values of the categorical features by numerical values using skelearn's LabelEncoder \n",
    "#The coding is in alphabetic order\n",
    "from sklearn.preprocessing  import LabelEncoder \n",
    "lb_make = LabelEncoder()\n",
    "cat_data= lb_make.fit_transform(cat_data)\n",
    "cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33411343, 0.80780972, 2.        ],\n",
       "       [0.02482294, 0.45455455, 0.        ],\n",
       "       [0.15375505, 0.77538588, 1.        ],\n",
       "       [0.04623018, 0.80065508, 2.        ],\n",
       "       [0.11466097, 0.73561668, 2.        ],\n",
       "       [0.09044322, 0.68652931, 0.        ],\n",
       "       [0.30915452, 0.54922504, 0.        ],\n",
       "       [0.61327427, 0.60722644, 1.        ],\n",
       "       [0.80411887, 0.85150846, 2.        ],\n",
       "       [0.12623851, 0.25971377, 2.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original Dataset\n",
    "all=np.insert(num_data,num_data.shape[1],cat_data,1)\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create one-hot encoded matrix for the categorical feature\n",
    "#Also it can be done with get_dummies from Pandas, Labelbinarizer and One-hot Enonder from scikit-learn\n",
    "one_hot_encoded_cat_data = np.eye(cat_data.max()+1)[cat_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_cat_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us consider a target attribute\n",
    "target =[0,1,1,1,1,0,1,1,1,0]\n",
    "target=np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the suggested  embedding size \n",
    "no_of_unique_cat  = len(np.unique(cat_data))\n",
    "#embedding size = min(50, number of categories/2).\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "embedding_size = int(embedding_size)\n",
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Input layers, specify input shape (dimensions except first)\n",
    "inp_cat_data = keras.layers.Input(shape=(no_of_unique_cat,))\n",
    "inp_num_data = keras.layers.Input(shape=(num_data.shape[1],))\n",
    "# Bind nulti_hot to embedding layer\n",
    "emb = keras.layers.Embedding(input_dim=no_of_unique_cat, output_dim=embedding_size)(inp_cat_data)  \n",
    "# Also you need flatten embedded output-\n",
    "# otherwise it's not possible to concatenate it with inp_num_data\n",
    "flatten = keras.layers.Flatten()(emb)\n",
    "# Concatenate two layers\n",
    "conc = keras.layers.Concatenate()([flatten, inp_num_data])\n",
    "dense1 = keras.layers.Dense(3, activation=tf.nn.relu, )(conc)\n",
    "# Creating output layer\n",
    "out = keras.layers.Dense(1, activation=None)(dense1)\n",
    "model = keras.Model(inputs=[inp_cat_data, inp_num_data], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 3, 2)         6           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 6)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8)            0           flatten_2[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            27          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            4           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(0.01),\n",
    "              loss=keras.losses.mean_squared_error,\n",
    "              metrics=[keras.metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E89437BAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.7706 - mean_squared_error: 0.7706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04003588, -0.0086223 ],\n",
       "       [-0.04412245,  0.03312165],\n",
       "       [ 0.00952185, -0.04416777]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding out the weights for each value of the categorical variable\n",
    "model.fit([one_hot_encoded_cat_data, num_data], target)\n",
    "model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.022, -0.012],\n",
       "       [-0.022,  0.047],\n",
       "       [-0.023,  0.038],\n",
       "       [-0.022, -0.012],\n",
       "       [-0.022, -0.012],\n",
       "       [-0.022,  0.047],\n",
       "       [-0.022,  0.047],\n",
       "       [-0.023,  0.038],\n",
       "       [-0.022, -0.012],\n",
       "       [-0.022, -0.012]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtaining the transformed representation of the categorial feature\n",
    "idx0=np.argwhere(cat_data==0)\n",
    "idx1=np.argwhere(cat_data==1)\n",
    "idx2=np.argwhere(cat_data==2)\n",
    "newcode=np.zeros((10,2))\n",
    "newcode[idx0,]=[-0.022, 0.047]\n",
    "newcode[idx1,]=[-0.023, 0.038]\n",
    "newcode[idx2,]=[-0.022,  -0.012]\n",
    "newcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21572427,  0.94465752, -0.022     , -0.012     ],\n",
       "       [ 0.13901493,  0.70445493, -0.022     ,  0.047     ],\n",
       "       [ 0.99609492,  0.33012453, -0.023     ,  0.038     ],\n",
       "       [ 0.17405204,  0.45957256, -0.022     , -0.012     ],\n",
       "       [ 0.53931295,  0.46135914, -0.022     , -0.012     ],\n",
       "       [ 0.13809674,  0.44709299, -0.022     ,  0.047     ],\n",
       "       [ 0.27858511,  0.46395601, -0.022     ,  0.047     ],\n",
       "       [ 0.17667699,  0.103717  , -0.023     ,  0.038     ],\n",
       "       [ 0.04629038,  0.64155933, -0.022     , -0.012     ],\n",
       "       [ 0.06945534,  0.10670777, -0.022     , -0.012     ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trnasformed dataset\n",
    "all1=np.insert(num_data,num_data.shape[1],np.transpose(newcode),1)\n",
    "all1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
