{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining and Machine Learning \n",
    "### Logistic Regression\n",
    "###  Libraries: scikit-learn and h2o\n",
    "#### Edgar Acuna\n",
    "#### Marzo 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54323 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 min 16 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/La_Paz</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>10 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_eacun_dndsro</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.947 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         1 min 16 secs\n",
       "H2O_cluster_timezone:       America/La_Paz\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.1\n",
       "H2O_cluster_version_age:    10 days\n",
       "H2O_cluster_name:           H2O_from_python_eacun_dndsro\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.947 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54323\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h2o\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.naive_bayes import H2ONaiveBayesEstimator\n",
    "from h2o.estimators.glm   import H2OGeneralizedLinearEstimator\n",
    "#h2o.connect()\n",
    "#h2o.no_progress()\n",
    "h2o.init(ip=\"localhost\", port=54323)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Predicting the final grade in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E1  pass\n",
      "0   96     1\n",
      "1   96     1\n",
      "2  100     1\n",
      "3   93     1\n",
      "4   90     1\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"http://academic.uprm.edu/eacuna/eje1dis.csv\")\n",
    "#Convirtiendo en matriz la tabla de predictoras y la columna de clases\n",
    "y=df['Nota']\n",
    "X=df.iloc[:,0:2]\n",
    "#creando una columna \"pass\" numerica para representar las clases\n",
    "lb_make = LabelEncoder()\n",
    "df[\"pass\"] = lb_make.fit_transform(df[\"Nota\"])\n",
    "databin=df[['E1','pass']]\n",
    "print(databin.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Trazando la linea de regresion sobre el plot de puntos\n",
    "x1=databin.iloc[:,0]\n",
    "x2=databin.iloc[:,1]\n",
    "plt.scatter(x1,x2)\n",
    "plt.plot(x1, np.poly1d(np.polyfit(x1, x2, 1))(x1),color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Logistic Regression to predict Final Grade. Use of sckikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes del modelo [[0.84415919 0.5817652 ]]\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression to predict Final Grade\n",
    "X=df[['E1',\"E2\"]]\n",
    "y3=df['pass']\n",
    "#Haciendo la regresion logistica ya calculando su precision\n",
    "model = LogisticRegression(solver=\"newton-cg\")\n",
    "model = model.fit(X, y3)\n",
    "print(\"Coeficientes del modelo\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "model.score(X,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Tasa de precision\n",
    "pred = model.predict(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "pred1=model.predict_proba(X)\n",
    "print(pred1[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y3, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficando la frontera de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "logis = LogisticRegression(solver=\"newton-cg\")\n",
    "X1=df.iloc[:,0:2].to_numpy()\n",
    "y1=df['pass'].to_numpy()\n",
    "logis.fit(X1,y1)\n",
    "eje1=np.arange(start = X1[:, 0].min()-1, stop = X1[:, 0].max() + 1, step = 0.1)\n",
    "eje2=np.arange(start = X1[:, 1].min()-1, stop = X1[:, 1].max() + 1, step = 0.11)\n",
    "Y1, Y2 = np.meshgrid(eje1,eje2)\n",
    "pred2=logis.predict(np.c_[Y1.ravel(), Y2.ravel()]).reshape(Y1.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(Y1, Y2, pred2,cmap=plt.cm.Paired)\n",
    "# Plot also the training points#\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, edgecolors='k')\n",
    "plt.xlabel('Ex1')\n",
    "plt.ylabel('Ex2')\n",
    "plt.xlim(Y1.min(), Y1.max())\n",
    "plt.ylim(Y2.min(), Y2.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using library H2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df1=h2o.H2OFrame(df)\n",
    "myx=['E1','E2']\n",
    "myy='Nota'\n",
    "glm_model = H2OGeneralizedLinearEstimator(family= \"binomial\", lambda_ = 0, compute_p_values = True) #Lmbda es un parametro de regularizacion\n",
    "glm_model.train(myx, myy, training_frame= df1)\n",
    "y_pred=glm_model.predict(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print((y_pred['predict']==df1['Nota']).sum()/len(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2. Logistic Regression for Diabetes using sckit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.17252327e-01  3.35996385e-02 -1.40874293e-02 -1.27054664e-03\n",
      "  -1.24031009e-03  7.72025616e-02  1.41904108e+00  1.00355496e-02]]\n"
     ]
    }
   ],
   "source": [
    "url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "#The response  variable must be binary (0,1)\n",
    "y=data['class']-1\n",
    "X=data.iloc[:,0:8]\n",
    "#Haciendo la regresion logistica y calculando su precision\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825520833333334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       500\n",
      "           1       0.74      0.57      0.65       268\n",
      "\n",
      "    accuracy                           0.78       768\n",
      "   macro avg       0.77      0.73      0.75       768\n",
      "weighted avg       0.78      0.78      0.77       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the accuracy using 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.771 (+/- 0.081)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "scores\n",
    "#Hallando la precision media y un intervalo de confianza \n",
    "print(\"CV Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression for Diabetes  using the H2o library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "diabetes = h2o.import_file(\"https://academic.uprm.edu/eacuna/diabetes.dat\")\n",
    "myx=['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8']\n",
    "diabetes['C9']=diabetes['C9'].asfactor()\n",
    "myy='C9'\n",
    "glm_model = H2OGeneralizedLinearEstimator(family= \"binomial\", lambda_ = 0, compute_p_values = True)\n",
    "glm_model.train(myx, myy, training_frame= diabetes)\n",
    "y_pred=glm_model.predict(diabetes)\n",
    "#print (y_pred['predict']==diabetes['C9']).sum()/float(len(diabetes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7669270833333334\n"
     ]
    }
   ],
   "source": [
    "print((y_pred['predict']==diabetes['C9']).sum()/len(diabetes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the accuracy using 10-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1617586914242_5\n",
      "\n",
      "\n",
      "GLM Model: summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>link</th>\n",
       "      <th>regularization</th>\n",
       "      <th>number_of_predictors_total</th>\n",
       "      <th>number_of_active_predictors</th>\n",
       "      <th>number_of_iterations</th>\n",
       "      <th>training_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>binomial</td>\n",
       "      <td>logit</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>py_2_sid_ab38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       family   link regularization  number_of_predictors_total  \\\n",
       "0    binomial  logit           None                           8   \n",
       "\n",
       "  number_of_active_predictors  number_of_iterations training_frame  \n",
       "0                           8                     5  py_2_sid_ab38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1527257557008024\n",
      "RMSE: 0.39080142745491914\n",
      "LogLoss: 0.47099308448839067\n",
      "Null degrees of freedom: 767\n",
      "Residual degrees of freedom: 759\n",
      "Null deviance: 993.4839101388008\n",
      "Residual deviance: 723.4453777741682\n",
      "AIC: 741.4453777741682\n",
      "AUC: 0.8393582089552238\n",
      "AUCPR: 0.7295945336147411\n",
      "Gini: 0.6787164179104477\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3543835358075865: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>392.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.216</td>\n",
       "      <td>(108.0/500.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>(70.0/268.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>462.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>(178.0/768.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1      2   Error            Rate\n",
       "0      1  392.0  108.0   0.216   (108.0/500.0)\n",
       "1      2   70.0  198.0  0.2612    (70.0/268.0)\n",
       "2  Total  462.0  306.0  0.2318   (178.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.354384</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.150764</td>\n",
       "      <td>0.801001</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.486768</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.486768</td>\n",
       "      <td>0.510942</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.331064</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.354384</td>\n",
       "      <td>0.761403</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992589</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.354384    0.689895  199.0\n",
       "1                        max f2   0.150764    0.801001  297.0\n",
       "2                  max f0point5   0.647587    0.710227  102.0\n",
       "3                  max accuracy   0.486768    0.785156  148.0\n",
       "4                 max precision   0.992589    1.000000    0.0\n",
       "5                    max recall   0.013685    1.000000  392.0\n",
       "6               max specificity   0.992589    1.000000    0.0\n",
       "7              max absolute_mcc   0.486768    0.510942  148.0\n",
       "8    max min_per_class_accuracy   0.331064    0.753731  207.0\n",
       "9   max mean_per_class_accuracy   0.354384    0.761403  199.0\n",
       "10                      max tns   0.992589  500.000000    0.0\n",
       "11                      max fns   0.992589  267.000000    0.0\n",
       "12                      max fps   0.001992  500.000000  399.0\n",
       "13                      max tps   0.013685  268.000000  392.0\n",
       "14                      max tnr   0.992589    1.000000    0.0\n",
       "15                      max fnr   0.992589    0.996269    0.0\n",
       "16                      max fpr   0.001992    1.000000  399.0\n",
       "17                      max tpr   0.013685    1.000000  392.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 27.29 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.568880</td>\n",
       "      <td>2.149254</td>\n",
       "      <td>2.149254</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.667991</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.667991</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>114.925373</td>\n",
       "      <td>114.925373</td>\n",
       "      <td>0.018388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.550826</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>1.253731</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.559291</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.613641</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.026119</td>\n",
       "      <td>-64.179104</td>\n",
       "      <td>25.373134</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.518522</td>\n",
       "      <td>1.432836</td>\n",
       "      <td>1.313433</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536097</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.587793</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>43.283582</td>\n",
       "      <td>31.343284</td>\n",
       "      <td>0.015045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040365</td>\n",
       "      <td>0.477280</td>\n",
       "      <td>1.637527</td>\n",
       "      <td>1.386615</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.490627</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.565852</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>63.752665</td>\n",
       "      <td>38.661531</td>\n",
       "      <td>0.023970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.451476</td>\n",
       "      <td>1.432836</td>\n",
       "      <td>1.396096</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461079</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.544360</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.070896</td>\n",
       "      <td>43.283582</td>\n",
       "      <td>39.609644</td>\n",
       "      <td>0.030896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100260</td>\n",
       "      <td>0.382335</td>\n",
       "      <td>1.659073</td>\n",
       "      <td>1.525877</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.477707</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.152985</td>\n",
       "      <td>65.907306</td>\n",
       "      <td>52.587711</td>\n",
       "      <td>0.080985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.348819</td>\n",
       "      <td>1.396096</td>\n",
       "      <td>1.482244</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.366186</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.440213</td>\n",
       "      <td>0.070896</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>39.609644</td>\n",
       "      <td>48.224395</td>\n",
       "      <td>0.111881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.326530</td>\n",
       "      <td>1.734485</td>\n",
       "      <td>1.544485</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.337709</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.414920</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>0.309701</td>\n",
       "      <td>73.448547</td>\n",
       "      <td>54.448537</td>\n",
       "      <td>0.167701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.294392</td>\n",
       "      <td>1.079279</td>\n",
       "      <td>1.389417</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.379586</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>7.927893</td>\n",
       "      <td>38.941655</td>\n",
       "      <td>0.179910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399740</td>\n",
       "      <td>0.267206</td>\n",
       "      <td>1.018068</td>\n",
       "      <td>1.297487</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.280489</td>\n",
       "      <td>0.452769</td>\n",
       "      <td>0.355054</td>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.518657</td>\n",
       "      <td>1.806756</td>\n",
       "      <td>29.748651</td>\n",
       "      <td>0.182657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250287</td>\n",
       "      <td>0.744330</td>\n",
       "      <td>1.186567</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.257372</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.335467</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.593284</td>\n",
       "      <td>-25.566970</td>\n",
       "      <td>18.656716</td>\n",
       "      <td>0.143284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600260</td>\n",
       "      <td>0.236007</td>\n",
       "      <td>0.781547</td>\n",
       "      <td>1.118917</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.242328</td>\n",
       "      <td>0.390456</td>\n",
       "      <td>0.319910</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>-21.845319</td>\n",
       "      <td>11.891734</td>\n",
       "      <td>0.109642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.219961</td>\n",
       "      <td>0.904949</td>\n",
       "      <td>1.088635</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.228202</td>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>-9.505106</td>\n",
       "      <td>8.863504</td>\n",
       "      <td>0.095194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799479</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.930413</td>\n",
       "      <td>1.068793</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.372964</td>\n",
       "      <td>0.295109</td>\n",
       "      <td>0.093284</td>\n",
       "      <td>0.854478</td>\n",
       "      <td>-6.958713</td>\n",
       "      <td>6.879284</td>\n",
       "      <td>0.084478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899740</td>\n",
       "      <td>0.189588</td>\n",
       "      <td>0.595464</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>0.354559</td>\n",
       "      <td>0.284263</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.914179</td>\n",
       "      <td>-40.453576</td>\n",
       "      <td>1.604856</td>\n",
       "      <td>0.022179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133485</td>\n",
       "      <td>0.855980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.170903</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.272898</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14.402016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010417         0.568880  2.149254   \n",
       "1       2                  0.020833         0.550826  0.358209   \n",
       "2       3                  0.031250         0.518522  1.432836   \n",
       "3       4                  0.040365         0.477280  1.637527   \n",
       "4       5                  0.050781         0.451476  1.432836   \n",
       "5       6                  0.100260         0.382335  1.659073   \n",
       "6       7                  0.151042         0.348819  1.396096   \n",
       "7       8                  0.200521         0.326530  1.734485   \n",
       "8       9                  0.300781         0.294392  1.079279   \n",
       "9      10                  0.399740         0.267206  1.018068   \n",
       "10     11                  0.500000         0.250287  0.744330   \n",
       "11     12                  0.600260         0.236007  0.781547   \n",
       "12     13                  0.699219         0.219961  0.904949   \n",
       "13     14                  0.799479         0.205380  0.930413   \n",
       "14     15                  0.899740         0.189588  0.595464   \n",
       "15     16                  1.000000         0.133485  0.855980   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.149254       0.750000  0.667991                  0.750000   \n",
       "1          1.253731       0.125000  0.559291                  0.437500   \n",
       "2          1.313433       0.500000  0.536097                  0.458333   \n",
       "3          1.386615       0.571429  0.490627                  0.483871   \n",
       "4          1.396096       0.500000  0.461079                  0.487179   \n",
       "5          1.525877       0.578947  0.409300                  0.532468   \n",
       "6          1.482244       0.487179  0.366186                  0.517241   \n",
       "7          1.544485       0.605263  0.337709                  0.538961   \n",
       "8          1.389417       0.376623  0.308918                  0.484848   \n",
       "9          1.297487       0.355263  0.280489                  0.452769   \n",
       "10         1.186567       0.259740  0.257372                  0.414062   \n",
       "11         1.118917       0.272727  0.242328                  0.390456   \n",
       "12         1.088635       0.315789  0.228202                  0.379888   \n",
       "13         1.068793       0.324675  0.212667                  0.372964   \n",
       "14         1.016049       0.207792  0.197775                  0.354559   \n",
       "15         1.000000       0.298701  0.170903                  0.348958   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.667991      0.022388                 0.022388  114.925373   \n",
       "1           0.613641      0.003731                 0.026119  -64.179104   \n",
       "2           0.587793      0.014925                 0.041045   43.283582   \n",
       "3           0.565852      0.014925                 0.055970   63.752665   \n",
       "4           0.544360      0.014925                 0.070896   43.283582   \n",
       "5           0.477707      0.082090                 0.152985   65.907306   \n",
       "6           0.440213      0.070896                 0.223881   39.609644   \n",
       "7           0.414920      0.085821                 0.309701   73.448547   \n",
       "8           0.379586      0.108209                 0.417910    7.927893   \n",
       "9           0.355054      0.100746                 0.518657    1.806756   \n",
       "10          0.335467      0.074627                 0.593284  -25.566970   \n",
       "11          0.319910      0.078358                 0.671642  -21.845319   \n",
       "12          0.306931      0.089552                 0.761194   -9.505106   \n",
       "13          0.295109      0.093284                 0.854478   -6.958713   \n",
       "14          0.284263      0.059701                 0.914179  -40.453576   \n",
       "15          0.272898      0.085821                 1.000000  -14.402016   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        114.925373            0.018388  \n",
       "1         25.373134            0.008119  \n",
       "2         31.343284            0.015045  \n",
       "3         38.661531            0.023970  \n",
       "4         39.609644            0.030896  \n",
       "5         52.587711            0.080985  \n",
       "6         48.224395            0.111881  \n",
       "7         54.448537            0.167701  \n",
       "8         38.941655            0.179910  \n",
       "9         29.748651            0.182657  \n",
       "10        18.656716            0.143284  \n",
       "11        11.891734            0.109642  \n",
       "12         8.863504            0.095194  \n",
       "13         6.879284            0.084478  \n",
       "14         1.604856            0.022179  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.156533279895907\n",
      "RMSE: 0.3956428691331451\n",
      "LogLoss: 0.48291477310031944\n",
      "Null degrees of freedom: 767\n",
      "Residual degrees of freedom: 759\n",
      "Null deviance: 995.478673759428\n",
      "Residual deviance: 741.7570914820907\n",
      "AIC: 759.7570914820907\n",
      "AUC: 0.83175\n",
      "AUCPR: 0.7135518209753184\n",
      "Gini: 0.6635\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.332458409050631: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>379.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.242</td>\n",
       "      <td>(121.0/500.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(67.0/268.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>446.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>(188.0/768.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1      2   Error            Rate\n",
       "0      1  379.0  121.0   0.242   (121.0/500.0)\n",
       "1      2   67.0  201.0    0.25    (67.0/268.0)\n",
       "2  Total  446.0  322.0  0.2448   (188.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.681356</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.155496</td>\n",
       "      <td>0.797604</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.511902</td>\n",
       "      <td>0.699627</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.500646</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.500646</td>\n",
       "      <td>0.501219</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.332458    0.681356  211.0\n",
       "1                        max f2   0.155496    0.797604  300.0\n",
       "2                  max f0point5   0.511902    0.699627  144.0\n",
       "3                  max accuracy   0.500646    0.781250  150.0\n",
       "4                 max precision   0.990396    1.000000    0.0\n",
       "5                    max recall   0.008668    1.000000  396.0\n",
       "6               max specificity   0.990396    1.000000    0.0\n",
       "7              max absolute_mcc   0.500646    0.501219  150.0\n",
       "8    max min_per_class_accuracy   0.332458    0.750000  211.0\n",
       "9   max mean_per_class_accuracy   0.332458    0.754000  211.0\n",
       "10                      max tns   0.990396  500.000000    0.0\n",
       "11                      max fns   0.990396  267.000000    0.0\n",
       "12                      max fps   0.001797  500.000000  399.0\n",
       "13                      max tps   0.008668  268.000000  396.0\n",
       "14                      max tnr   0.990396    1.000000    0.0\n",
       "15                      max fnr   0.990396    0.996269    0.0\n",
       "16                      max fpr   0.001797    1.000000  399.0\n",
       "17                      max tpr   0.008668    1.000000  396.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 292.10 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>5.594972</td>\n",
       "      <td>1.791045</td>\n",
       "      <td>1.791045</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.078711</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.078711</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>79.104478</td>\n",
       "      <td>79.104478</td>\n",
       "      <td>0.012657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>5.005626</td>\n",
       "      <td>2.149254</td>\n",
       "      <td>1.970149</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.371931</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>5.725321</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>114.925373</td>\n",
       "      <td>97.014925</td>\n",
       "      <td>0.031045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>3.725241</td>\n",
       "      <td>1.074627</td>\n",
       "      <td>1.671642</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>4.395799</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>5.282147</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>7.462687</td>\n",
       "      <td>67.164179</td>\n",
       "      <td>0.032239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040365</td>\n",
       "      <td>3.568273</td>\n",
       "      <td>2.865672</td>\n",
       "      <td>1.941261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.635529</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>4.910330</td>\n",
       "      <td>0.026119</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>186.567164</td>\n",
       "      <td>94.126143</td>\n",
       "      <td>0.058358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>3.509211</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>1.690011</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.541895</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>4.629625</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>-28.358209</td>\n",
       "      <td>69.001148</td>\n",
       "      <td>0.053821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100260</td>\n",
       "      <td>3.271007</td>\n",
       "      <td>1.282011</td>\n",
       "      <td>1.488661</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>3.366544</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>4.006286</td>\n",
       "      <td>0.063433</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>28.201100</td>\n",
       "      <td>48.866059</td>\n",
       "      <td>0.075254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>3.162886</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>1.309315</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.207956</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>3.737882</td>\n",
       "      <td>0.048507</td>\n",
       "      <td>0.197761</td>\n",
       "      <td>-4.477612</td>\n",
       "      <td>30.931549</td>\n",
       "      <td>0.071761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>3.090552</td>\n",
       "      <td>0.603299</td>\n",
       "      <td>1.135104</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>3.126742</td>\n",
       "      <td>0.396104</td>\n",
       "      <td>3.587081</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.227612</td>\n",
       "      <td>-39.670071</td>\n",
       "      <td>13.510370</td>\n",
       "      <td>0.041612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>2.990087</td>\n",
       "      <td>1.042062</td>\n",
       "      <td>1.104090</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>3.035653</td>\n",
       "      <td>0.385281</td>\n",
       "      <td>3.403272</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.332090</td>\n",
       "      <td>4.206242</td>\n",
       "      <td>10.408994</td>\n",
       "      <td>0.048090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399740</td>\n",
       "      <td>2.913986</td>\n",
       "      <td>1.018068</td>\n",
       "      <td>1.082794</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>2.951350</td>\n",
       "      <td>0.377850</td>\n",
       "      <td>3.291395</td>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>1.806756</td>\n",
       "      <td>8.279450</td>\n",
       "      <td>0.050836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.828723</td>\n",
       "      <td>1.265362</td>\n",
       "      <td>1.119403</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>2.870604</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>3.207018</td>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.559701</td>\n",
       "      <td>26.536150</td>\n",
       "      <td>11.940299</td>\n",
       "      <td>0.091701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600260</td>\n",
       "      <td>2.763231</td>\n",
       "      <td>0.893196</td>\n",
       "      <td>1.081620</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>2.798380</td>\n",
       "      <td>0.377440</td>\n",
       "      <td>3.138764</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>-10.680364</td>\n",
       "      <td>8.162010</td>\n",
       "      <td>0.075254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>2.697330</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>1.029934</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.731281</td>\n",
       "      <td>0.359404</td>\n",
       "      <td>3.081094</td>\n",
       "      <td>0.070896</td>\n",
       "      <td>0.720149</td>\n",
       "      <td>-28.358209</td>\n",
       "      <td>2.993413</td>\n",
       "      <td>0.032149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799479</td>\n",
       "      <td>2.625676</td>\n",
       "      <td>0.893196</td>\n",
       "      <td>1.012786</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>2.661374</td>\n",
       "      <td>0.353420</td>\n",
       "      <td>3.028458</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>-10.680364</td>\n",
       "      <td>1.278623</td>\n",
       "      <td>0.015701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899740</td>\n",
       "      <td>2.518550</td>\n",
       "      <td>1.042062</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.578475</td>\n",
       "      <td>0.354559</td>\n",
       "      <td>2.978315</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.914179</td>\n",
       "      <td>4.206242</td>\n",
       "      <td>1.604856</td>\n",
       "      <td>0.022179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.229647</td>\n",
       "      <td>0.855980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>2.406791</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>2.921014</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14.402016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010417         5.594972  1.791045   \n",
       "1       2                  0.020833         5.005626  2.149254   \n",
       "2       3                  0.031250         3.725241  1.074627   \n",
       "3       4                  0.040365         3.568273  2.865672   \n",
       "4       5                  0.050781         3.509211  0.716418   \n",
       "5       6                  0.100260         3.271007  1.282011   \n",
       "6       7                  0.151042         3.162886  0.955224   \n",
       "7       8                  0.200521         3.090552  0.603299   \n",
       "8       9                  0.300781         2.990087  1.042062   \n",
       "9      10                  0.399740         2.913986  1.018068   \n",
       "10     11                  0.500000         2.828723  1.265362   \n",
       "11     12                  0.600260         2.763231  0.893196   \n",
       "12     13                  0.699219         2.697330  0.716418   \n",
       "13     14                  0.799479         2.625676  0.893196   \n",
       "14     15                  0.899740         2.518550  1.042062   \n",
       "15     16                  1.000000         2.229647  0.855980   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.791045       0.625000  6.078711                  0.625000   \n",
       "1          1.970149       0.750000  5.371931                  0.687500   \n",
       "2          1.671642       0.375000  4.395799                  0.583333   \n",
       "3          1.941261       1.000000  3.635529                  0.677419   \n",
       "4          1.690011       0.250000  3.541895                  0.589744   \n",
       "5          1.488661       0.447368  3.366544                  0.519481   \n",
       "6          1.309315       0.333333  3.207956                  0.456897   \n",
       "7          1.135104       0.210526  3.126742                  0.396104   \n",
       "8          1.104090       0.363636  3.035653                  0.385281   \n",
       "9          1.082794       0.355263  2.951350                  0.377850   \n",
       "10         1.119403       0.441558  2.870604                  0.390625   \n",
       "11         1.081620       0.311688  2.798380                  0.377440   \n",
       "12         1.029934       0.250000  2.731281                  0.359404   \n",
       "13         1.012786       0.311688  2.661374                  0.353420   \n",
       "14         1.016049       0.363636  2.578475                  0.354559   \n",
       "15         1.000000       0.298701  2.406791                  0.348958   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           6.078711      0.018657                 0.018657   79.104478   \n",
       "1           5.725321      0.022388                 0.041045  114.925373   \n",
       "2           5.282147      0.011194                 0.052239    7.462687   \n",
       "3           4.910330      0.026119                 0.078358  186.567164   \n",
       "4           4.629625      0.007463                 0.085821  -28.358209   \n",
       "5           4.006286      0.063433                 0.149254   28.201100   \n",
       "6           3.737882      0.048507                 0.197761   -4.477612   \n",
       "7           3.587081      0.029851                 0.227612  -39.670071   \n",
       "8           3.403272      0.104478                 0.332090    4.206242   \n",
       "9           3.291395      0.100746                 0.432836    1.806756   \n",
       "10          3.207018      0.126866                 0.559701   26.536150   \n",
       "11          3.138764      0.089552                 0.649254  -10.680364   \n",
       "12          3.081094      0.070896                 0.720149  -28.358209   \n",
       "13          3.028458      0.089552                 0.809701  -10.680364   \n",
       "14          2.978315      0.104478                 0.914179    4.206242   \n",
       "15          2.921014      0.085821                 1.000000  -14.402016   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         79.104478            0.012657  \n",
       "1         97.014925            0.031045  \n",
       "2         67.164179            0.032239  \n",
       "3         94.126143            0.058358  \n",
       "4         69.001148            0.053821  \n",
       "5         48.866059            0.075254  \n",
       "6         30.931549            0.071761  \n",
       "7         13.510370            0.041612  \n",
       "8         10.408994            0.048090  \n",
       "9          8.279450            0.050836  \n",
       "10        11.940299            0.091701  \n",
       "11         8.162010            0.075254  \n",
       "12         2.993413            0.032149  \n",
       "13         1.278623            0.015701  \n",
       "14         1.604856            0.022179  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "      <th>cv_6_valid</th>\n",
       "      <th>cv_7_valid</th>\n",
       "      <th>cv_8_valid</th>\n",
       "      <th>cv_9_valid</th>\n",
       "      <th>cv_10_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.78202814</td>\n",
       "      <td>0.06163615</td>\n",
       "      <td>0.74025977</td>\n",
       "      <td>0.78205127</td>\n",
       "      <td>0.67105263</td>\n",
       "      <td>0.84931505</td>\n",
       "      <td>0.7972973</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.69135803</td>\n",
       "      <td>0.8333333</td>\n",
       "      <td>0.82666665</td>\n",
       "      <td>0.82894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8300141</td>\n",
       "      <td>0.04805236</td>\n",
       "      <td>0.82819074</td>\n",
       "      <td>0.85257804</td>\n",
       "      <td>0.7362056</td>\n",
       "      <td>0.85826087</td>\n",
       "      <td>0.83928573</td>\n",
       "      <td>0.84313726</td>\n",
       "      <td>0.7557377</td>\n",
       "      <td>0.8733286</td>\n",
       "      <td>0.8284734</td>\n",
       "      <td>0.8849432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aucpr</td>\n",
       "      <td>0.7231223</td>\n",
       "      <td>0.096908376</td>\n",
       "      <td>0.73505014</td>\n",
       "      <td>0.7706871</td>\n",
       "      <td>0.62480456</td>\n",
       "      <td>0.8045454</td>\n",
       "      <td>0.7966248</td>\n",
       "      <td>0.7032648</td>\n",
       "      <td>0.5171245</td>\n",
       "      <td>0.7725502</td>\n",
       "      <td>0.67166</td>\n",
       "      <td>0.8349113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err</td>\n",
       "      <td>0.21797186</td>\n",
       "      <td>0.06163615</td>\n",
       "      <td>0.25974026</td>\n",
       "      <td>0.21794872</td>\n",
       "      <td>0.32894737</td>\n",
       "      <td>0.15068494</td>\n",
       "      <td>0.2027027</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30864197</td>\n",
       "      <td>0.16666667</td>\n",
       "      <td>0.17333333</td>\n",
       "      <td>0.17105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>err_count</td>\n",
       "      <td>16.8</td>\n",
       "      <td>5.0066624</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.6911892</td>\n",
       "      <td>0.09982281</td>\n",
       "      <td>0.6666667</td>\n",
       "      <td>0.67484665</td>\n",
       "      <td>0.56650245</td>\n",
       "      <td>0.8045977</td>\n",
       "      <td>0.7291667</td>\n",
       "      <td>0.71895427</td>\n",
       "      <td>0.48913044</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6967213</td>\n",
       "      <td>0.7653061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.7169748</td>\n",
       "      <td>0.061502054</td>\n",
       "      <td>0.7222222</td>\n",
       "      <td>0.72131145</td>\n",
       "      <td>0.64788735</td>\n",
       "      <td>0.71794873</td>\n",
       "      <td>0.7368421</td>\n",
       "      <td>0.73333335</td>\n",
       "      <td>0.59016395</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.7234042</td>\n",
       "      <td>0.82191783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.75581074</td>\n",
       "      <td>0.05999848</td>\n",
       "      <td>0.7878788</td>\n",
       "      <td>0.7746479</td>\n",
       "      <td>0.7565789</td>\n",
       "      <td>0.6481481</td>\n",
       "      <td>0.7446808</td>\n",
       "      <td>0.7482993</td>\n",
       "      <td>0.74380165</td>\n",
       "      <td>0.71428573</td>\n",
       "      <td>0.7522124</td>\n",
       "      <td>0.88757396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>1.0591292</td>\n",
       "      <td>1.3719791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8148148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>2.7586207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.48229143</td>\n",
       "      <td>0.052943923</td>\n",
       "      <td>0.52275217</td>\n",
       "      <td>0.45298007</td>\n",
       "      <td>0.58304197</td>\n",
       "      <td>0.40539712</td>\n",
       "      <td>0.47611466</td>\n",
       "      <td>0.4940024</td>\n",
       "      <td>0.5372022</td>\n",
       "      <td>0.4411642</td>\n",
       "      <td>0.4675887</td>\n",
       "      <td>0.44267094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.30373028</td>\n",
       "      <td>0.074060455</td>\n",
       "      <td>0.32608697</td>\n",
       "      <td>0.23529412</td>\n",
       "      <td>0.42857143</td>\n",
       "      <td>0.39130434</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2413793</td>\n",
       "      <td>0.37704918</td>\n",
       "      <td>0.31034482</td>\n",
       "      <td>0.22727273</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.5624768</td>\n",
       "      <td>0.08569114</td>\n",
       "      <td>0.5038653</td>\n",
       "      <td>0.55599403</td>\n",
       "      <td>0.41030496</td>\n",
       "      <td>0.6386037</td>\n",
       "      <td>0.57232237</td>\n",
       "      <td>0.57443404</td>\n",
       "      <td>0.45104393</td>\n",
       "      <td>0.63666975</td>\n",
       "      <td>0.60052866</td>\n",
       "      <td>0.68100154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.7841307</td>\n",
       "      <td>0.03543881</td>\n",
       "      <td>0.75631136</td>\n",
       "      <td>0.78976035</td>\n",
       "      <td>0.71164024</td>\n",
       "      <td>0.78434783</td>\n",
       "      <td>0.7880435</td>\n",
       "      <td>0.79107505</td>\n",
       "      <td>0.7614754</td>\n",
       "      <td>0.8040113</td>\n",
       "      <td>0.8108919</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.21586931</td>\n",
       "      <td>0.03543881</td>\n",
       "      <td>0.24368864</td>\n",
       "      <td>0.21023965</td>\n",
       "      <td>0.2883598</td>\n",
       "      <td>0.21565217</td>\n",
       "      <td>0.21195652</td>\n",
       "      <td>0.20892495</td>\n",
       "      <td>0.23852459</td>\n",
       "      <td>0.19598874</td>\n",
       "      <td>0.18910806</td>\n",
       "      <td>0.15625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.15634096</td>\n",
       "      <td>0.019596385</td>\n",
       "      <td>0.16938694</td>\n",
       "      <td>0.14949246</td>\n",
       "      <td>0.198471</td>\n",
       "      <td>0.12765439</td>\n",
       "      <td>0.15309586</td>\n",
       "      <td>0.15704177</td>\n",
       "      <td>0.17178269</td>\n",
       "      <td>0.14092916</td>\n",
       "      <td>0.14972077</td>\n",
       "      <td>0.14583448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>null_deviance</td>\n",
       "      <td>99.54787</td>\n",
       "      <td>5.259903</td>\n",
       "      <td>104.98886</td>\n",
       "      <td>100.62852</td>\n",
       "      <td>98.91423</td>\n",
       "      <td>91.42849</td>\n",
       "      <td>98.50513</td>\n",
       "      <td>104.854996</td>\n",
       "      <td>95.392075</td>\n",
       "      <td>103.16521</td>\n",
       "      <td>92.0487</td>\n",
       "      <td>105.55246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.7231223</td>\n",
       "      <td>0.096908376</td>\n",
       "      <td>0.73505014</td>\n",
       "      <td>0.7706871</td>\n",
       "      <td>0.62480456</td>\n",
       "      <td>0.8045454</td>\n",
       "      <td>0.7966248</td>\n",
       "      <td>0.7032648</td>\n",
       "      <td>0.5171245</td>\n",
       "      <td>0.7725502</td>\n",
       "      <td>0.67166</td>\n",
       "      <td>0.8349113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.6796813</td>\n",
       "      <td>0.13039653</td>\n",
       "      <td>0.63414633</td>\n",
       "      <td>0.64705884</td>\n",
       "      <td>0.52272725</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.7241379</td>\n",
       "      <td>0.7096774</td>\n",
       "      <td>0.4390244</td>\n",
       "      <td>0.8333333</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.73170733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.29989928</td>\n",
       "      <td>0.1126307</td>\n",
       "      <td>0.2957257</td>\n",
       "      <td>0.33949736</td>\n",
       "      <td>0.13350831</td>\n",
       "      <td>0.40846065</td>\n",
       "      <td>0.3491049</td>\n",
       "      <td>0.32044125</td>\n",
       "      <td>0.076175205</td>\n",
       "      <td>0.39661297</td>\n",
       "      <td>0.27771926</td>\n",
       "      <td>0.40174723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7922575</td>\n",
       "      <td>0.0980038</td>\n",
       "      <td>0.83870965</td>\n",
       "      <td>0.8148148</td>\n",
       "      <td>0.8518519</td>\n",
       "      <td>0.6086956</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.7586207</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6896552</td>\n",
       "      <td>0.77272725</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean           sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy  0.78202814   0.06163615  0.74025977  0.78205127   \n",
       "1                       auc   0.8300141   0.04805236  0.82819074  0.85257804   \n",
       "2                     aucpr   0.7231223  0.096908376  0.73505014   0.7706871   \n",
       "3                       err  0.21797186   0.06163615  0.25974026  0.21794872   \n",
       "4                 err_count        16.8    5.0066624        20.0        17.0   \n",
       "5                  f0point5   0.6911892   0.09982281   0.6666667  0.67484665   \n",
       "6                        f1   0.7169748  0.061502054   0.7222222  0.72131145   \n",
       "7                        f2  0.75581074   0.05999848   0.7878788   0.7746479   \n",
       "8            lift_top_group   1.0591292    1.3719791         0.0         0.0   \n",
       "9                   logloss  0.48229143  0.052943923  0.52275217  0.45298007   \n",
       "10      max_per_class_error  0.30373028  0.074060455  0.32608697  0.23529412   \n",
       "11                      mcc   0.5624768   0.08569114   0.5038653  0.55599403   \n",
       "12  mean_per_class_accuracy   0.7841307   0.03543881  0.75631136  0.78976035   \n",
       "13     mean_per_class_error  0.21586931   0.03543881  0.24368864  0.21023965   \n",
       "14                      mse  0.15634096  0.019596385  0.16938694  0.14949246   \n",
       "15            null_deviance    99.54787     5.259903   104.98886   100.62852   \n",
       "16                   pr_auc   0.7231223  0.096908376  0.73505014   0.7706871   \n",
       "17                precision   0.6796813   0.13039653  0.63414633  0.64705884   \n",
       "18                       r2  0.29989928    0.1126307   0.2957257  0.33949736   \n",
       "19                   recall   0.7922575    0.0980038  0.83870965   0.8148148   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  cv_6_valid   cv_7_valid  cv_8_valid  \\\n",
       "0   0.67105263  0.84931505   0.7972973         0.8   0.69135803   0.8333333   \n",
       "1    0.7362056  0.85826087  0.83928573  0.84313726    0.7557377   0.8733286   \n",
       "2   0.62480456   0.8045454   0.7966248   0.7032648    0.5171245   0.7725502   \n",
       "3   0.32894737  0.15068494   0.2027027         0.2   0.30864197  0.16666667   \n",
       "4         25.0        11.0        15.0        16.0         25.0        13.0   \n",
       "5   0.56650245   0.8045977   0.7291667  0.71895427   0.48913044         0.8   \n",
       "6   0.64788735  0.71794873   0.7368421  0.73333335   0.59016395    0.754717   \n",
       "7    0.7565789   0.6481481   0.7446808   0.7482993   0.74380165  0.71428573   \n",
       "8    2.8148148         0.0    2.642857   2.7586207          0.0         0.0   \n",
       "9   0.58304197  0.40539712  0.47611466   0.4940024    0.5372022   0.4411642   \n",
       "10  0.42857143  0.39130434        0.25   0.2413793   0.37704918  0.31034482   \n",
       "11  0.41030496   0.6386037  0.57232237  0.57443404   0.45104393  0.63666975   \n",
       "12  0.71164024  0.78434783   0.7880435  0.79107505    0.7614754   0.8040113   \n",
       "13   0.2883598  0.21565217  0.21195652  0.20892495   0.23852459  0.19598874   \n",
       "14    0.198471  0.12765439  0.15309586  0.15704177   0.17178269  0.14092916   \n",
       "15    98.91423    91.42849    98.50513  104.854996    95.392075   103.16521   \n",
       "16  0.62480456   0.8045454   0.7966248   0.7032648    0.5171245   0.7725502   \n",
       "17  0.52272725       0.875   0.7241379   0.7096774    0.4390244   0.8333333   \n",
       "18  0.13350831  0.40846065   0.3491049  0.32044125  0.076175205  0.39661297   \n",
       "19   0.8518519   0.6086956        0.75   0.7586207          0.9   0.6896552   \n",
       "\n",
       "    cv_9_valid cv_10_valid  \n",
       "0   0.82666665  0.82894737  \n",
       "1    0.8284734   0.8849432  \n",
       "2      0.67166   0.8349113  \n",
       "3   0.17333333  0.17105263  \n",
       "4         13.0        13.0  \n",
       "5    0.6967213   0.7653061  \n",
       "6    0.7234042  0.82191783  \n",
       "7    0.7522124  0.88757396  \n",
       "8          0.0       2.375  \n",
       "9    0.4675887  0.44267094  \n",
       "10  0.22727273        0.25  \n",
       "11  0.60052866  0.68100154  \n",
       "12   0.8108919     0.84375  \n",
       "13  0.18910806     0.15625  \n",
       "14  0.14972077  0.14583448  \n",
       "15     92.0487   105.55246  \n",
       "16     0.67166   0.8349113  \n",
       "17        0.68  0.73170733  \n",
       "18  0.27771926  0.40174723  \n",
       "19  0.77272725      0.9375  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>iterations</th>\n",
       "      <th>negative_log_likelihood</th>\n",
       "      <th>objective</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_r2</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>0</td>\n",
       "      <td>496.741955</td>\n",
       "      <td>0.646799</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.001 sec</td>\n",
       "      <td>1</td>\n",
       "      <td>370.890960</td>\n",
       "      <td>0.482931</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.002 sec</td>\n",
       "      <td>2</td>\n",
       "      <td>362.029436</td>\n",
       "      <td>0.471392</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.002 sec</td>\n",
       "      <td>3</td>\n",
       "      <td>361.723247</td>\n",
       "      <td>0.470994</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.002 sec</td>\n",
       "      <td>4</td>\n",
       "      <td>361.722689</td>\n",
       "      <td>0.470993</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2021-04-04 21:44:14</td>\n",
       "      <td>0.003 sec</td>\n",
       "      <td>5</td>\n",
       "      <td>361.722689</td>\n",
       "      <td>0.470993</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.470993</td>\n",
       "      <td>0.327751</td>\n",
       "      <td>0.839358</td>\n",
       "      <td>0.729595</td>\n",
       "      <td>2.14925</td>\n",
       "      <td>0.231771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  iterations  negative_log_likelihood  \\\n",
       "0    2021-04-04 21:44:14   0.000 sec           0               496.741955   \n",
       "1    2021-04-04 21:44:14   0.001 sec           1               370.890960   \n",
       "2    2021-04-04 21:44:14   0.002 sec           2               362.029436   \n",
       "3    2021-04-04 21:44:14   0.002 sec           3               361.723247   \n",
       "4    2021-04-04 21:44:14   0.002 sec           4               361.722689   \n",
       "5    2021-04-04 21:44:14   0.003 sec           5               361.722689   \n",
       "\n",
       "   objective training_rmse training_logloss training_r2 training_auc  \\\n",
       "0   0.646799                                                           \n",
       "1   0.482931                                                           \n",
       "2   0.471392                                                           \n",
       "3   0.470994                                                           \n",
       "4   0.470993                                                           \n",
       "5   0.470993      0.390801         0.470993    0.327751     0.839358   \n",
       "\n",
       "  training_pr_auc training_lift training_classification_error  \n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5        0.729595       2.14925                      0.231771  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2</td>\n",
       "      <td>1.124276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C6</td>\n",
       "      <td>0.707217</td>\n",
       "      <td>0.629042</td>\n",
       "      <td>0.225289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.369191</td>\n",
       "      <td>0.132224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C7</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>0.278548</td>\n",
       "      <td>0.099761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3</td>\n",
       "      <td>0.257346</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.081980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C8</td>\n",
       "      <td>0.174863</td>\n",
       "      <td>0.155534</td>\n",
       "      <td>0.055704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C5</td>\n",
       "      <td>0.137336</td>\n",
       "      <td>0.122155</td>\n",
       "      <td>0.043749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C4</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable  relative_importance  scaled_importance  percentage\n",
       "0       C2             1.124276           1.000000    0.358147\n",
       "1       C6             0.707217           0.629042    0.225289\n",
       "2       C1             0.415072           0.369191    0.132224\n",
       "3       C7             0.313165           0.278548    0.099761\n",
       "4       C3             0.257346           0.228899    0.081980\n",
       "5       C8             0.174863           0.155534    0.055704\n",
       "6       C5             0.137336           0.122155    0.043749\n",
       "7       C4             0.009874           0.008782    0.003145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = H2OGeneralizedLinearEstimator(family= \"binomial\", lambda_ = 0, compute_p_values = True,nfolds=10)\n",
    "model.train(myx, myy, training_frame= diabetes)\n",
    "model.confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
